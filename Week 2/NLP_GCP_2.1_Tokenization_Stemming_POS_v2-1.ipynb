{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Class 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization, Stemming & Lemmatization, Part-of-speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('popular', halt_on_error=False)\n",
    "#nltk.download('all', halt_on_error=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests, sys\n",
    "import nltk as nltk\n",
    "import nltk.corpus  \n",
    "from nltk.text import Text\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \n",
      "[GCC 9.4.0]\n"
     ]
    }
   ],
   "source": [
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Flu', 'season', 'hitting', 'earlier', ',', 'with', 'dozens', 'more', 'outbreaks', '—', 'and', 'more', 'severe', 'symptoms']\n"
     ]
    }
   ],
   "source": [
    "text = \"Flu season hitting earlier, with dozens more outbreaks — and more severe symptoms\"\n",
    "tokens = nltk.tokenize.word_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy source data from GCS into local FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gcs_data (bucket_name, folder_name, file_name, local_folder_name):\n",
    "    url = 'https://storage.googleapis.com/' + bucket_name + '/' + folder_name + '/' + file_name\n",
    "    r = requests.get(url)\n",
    "    open(local_folder_name + '/' + file_name , 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: 3boat10.txt\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'msca-bdp-data-open'\n",
    "folder_name = 'books'\n",
    "file_name = ['3boat10.txt']\n",
    "local_folder_name = '/home/jupyter/data/books/'\n",
    "\n",
    "os.makedirs(local_folder_name, exist_ok=True)\n",
    "\n",
    "for file in file_name:\n",
    "    get_gcs_data (bucket_name = bucket_name,\n",
    "                 folder_name = folder_name,\n",
    "                 file_name = file,\n",
    "                 local_folder_name = local_folder_name)\n",
    "    print('Downloaded: ' + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get most frequent words in a book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 7778 samples and 79620 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(',', 5702),\n",
       " ('the', 3338),\n",
       " ('and', 3215),\n",
       " ('.', 3081),\n",
       " ('to', 1748),\n",
       " ('a', 1621),\n",
       " ('of', 1425),\n",
       " ('I', 1208),\n",
       " ('it', 1159),\n",
       " ('in', 931)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = local_folder_name + file_name[0]\n",
    "f = open(file_path)\n",
    "bk_3boat = f.read()\n",
    "\n",
    "words = nltk.tokenize.word_tokenize(bk_3boat)\n",
    "fdist = nltk.FreqDist(words)\n",
    "\n",
    "print(fdist)\n",
    "\n",
    "#fdist.items() - will give all words\n",
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get most frequent clean words in a book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 6232 samples and 29826 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('said', 378),\n",
       " ('would', 362),\n",
       " ('harris', 316),\n",
       " ('george', 308),\n",
       " ('one', 246),\n",
       " ('us', 228),\n",
       " ('boat', 186),\n",
       " ('get', 179),\n",
       " ('could', 175),\n",
       " ('got', 163)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from nltk.corpus import stopwords\n",
    "\n",
    "#default_stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "words = nltk.tokenize.word_tokenize(bk_3boat)\n",
    "\n",
    "#stopwords = stopwords.words('english')\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# Remove single-character tokens (mostly punctuation)\n",
    "words = [word for word in words if len(word) > 1]\n",
    "\n",
    "# Remove numbers\n",
    "#words = [word for word in words if not word.isnumeric()]\n",
    "\n",
    "# Remove punctuation\n",
    "words = [word for word in words if word.isalpha()]\n",
    "\n",
    "# Lowercase all words (default_stopwords are lowercase too)\n",
    "words_lc = [word.lower() for word in words]\n",
    "\n",
    "# Remove stopwords\n",
    "words_lc = [word for word in words_lc if word not in stopwords]\n",
    "\n",
    "# Remove stopwords\n",
    "# words = [word for word in words if word not in stopwords]\n",
    "\n",
    "\n",
    "fdist = nltk.FreqDist(words_lc)\n",
    "\n",
    "print(fdist)\n",
    "\n",
    "#fdist.items() - will give all words\n",
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have to instantiate a Text object first, and then call it on that object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "textList = Text(nltk.corpus.gutenberg.words(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A concordance view shows us every occurrence of a given word, together with some context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 199 matches:\n",
      "                                     BOAT ( TO SAY NOTHING OF THE DOG ). Three\n",
      "                                     Boat by Jerome K . Jerome CHAPTER I . THR\n",
      "ty of people very bad indeed , whole boat - loads of them ; but I never met a \n",
      " like a fellow I saw on the Yarmouth boat one day , I could account for the se\n",
      "ckles I ever tasted in a respectable boat . Did you have any ?\" For myself , I\n",
      "eep , you get fooling about with the boat , and slop me overboard . If you ask\n",
      "o down in the morning , and take the boat up to Chertsey , and George , who wo\n",
      "n stillness . Then we run our little boat into some quiet nook , and the tent \n",
      "talk , the river , playing round the boat , prattles strange old tales and sec\n",
      "is a good two inches of water in the boat , and all the things are damp . You \n",
      "rd man , who has been baling out the boat , and who has spilled the water down\n",
      "uld not allow of the navigation of a boat sufficiently large to take the thing\n",
      "eople , on that voyage , load up the boat till it is ever in danger of swampin\n",
      " ! Throw it overboard . It makes the boat so heavy to pull , you nearly faint \n",
      "row the lumber over , man ! Let your boat of life be light , packed with only \n",
      " dangerous thing . You will find the boat easier to pull then , and it will no\n",
      " suggested George ; \" we will have a boat with a cover . It is ever so much si\n",
      "ean . You fix iron hoops up over the boat , and stretch a huge canvas over the\n",
      " stem to stern , and it converts the boat into a sort of little house , and it\n",
      "it was so pleasant to wake up in the boat in the fresh morning , and plunge in\n",
      "ave Harris clean and fresh about the boat , even if we did have to take a few \n",
      "ooze . We kept it in the nose of the boat , and , from there , it oozed down t\n",
      " the rudder , impregnating the whole boat and everything in it on its way , an\n",
      "away from it at Marlow . We left the boat by the bridge , and took a walk thro\n",
      "r to take paraffine oil with us in a boat again - except , of course , in case\n"
     ]
    }
   ],
   "source": [
    "textList.concordance(\"boat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 88 matches:\n",
      " thin , not the captain ) and soda - water ; but , towards Saturday , he got up\n",
      "night ,\" and , lulled by the lapping water and the rustling trees , we fall asl\n",
      " , and there is a good two inches of water in the boat , and all the things are\n",
      "t the boat , and who has spilled the water down his sleeve , and has been cursi\n",
      " good , plain merchandise will stand water . You will have time to think as wel\n",
      "hen they are going anywhere near the water , but that they don ' t bathe much w\n",
      " , shivering , through six inches of water . And when I do get to the sea , it \n",
      " swimming for my life in two feet of water . I hop back and dress , and crawl h\n",
      "of Harris ' s , which you mixed with water and called lemonade , plenty of tea \n",
      "orted . \" Now we shan ' t get on the water till after twelve . I wonder you tak\n",
      "on , and prognosticate drought , and water famine , and sunstroke , and simooms\n",
      "the lower part of the town was under water , owing to the river having overflow\n",
      "ident he was the 9 . 32 for Virginia Water , or the 10 a . m . express for the \n",
      "ngston , where they came down to the water ' s edge , looked quite picturesque \n",
      " cloaked gallants swaggered down the water - steps to cry : \" What Ferry , ho !\n",
      "metimes , when you could not see any water at all , but only a brilliant tangle\n",
      "easant landscape , and the sparkling water , it is one of the gayest sights I k\n",
      "t was my misfortune once to go for a water picnic with two ladies of this kind \n",
      "anywhere near real earth , air , and water . The first thing was that they thou\n",
      "ing , and it appeared that a drop of water ruined those costumes . The mark nev\n",
      "m , and I picked out a smooth bit of water to drop them into again each time . \n",
      "ld not help an occasional flicker of water from going over those dresses . The \n",
      "e . When he spread more than pint of water over one of those dresses , he would\n",
      ", and sloush the things about in the water .\" The elder sister said that she wa\n",
      "n the hamper , and a gallon - jar of water in the nose of the boat , and that t\n"
     ]
    }
   ],
   "source": [
    "textList.concordance(\"water\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 31 matches:\n",
      "                                      DOG ). Three Men in a Boat by Jerome K . \n",
      "ed up at me , and think : \" Oh , that dog will never live . He will be snatched\n",
      "t door but one for having a ferocious dog at large , that had kept him pinned u\n",
      "e and someone to love you , a cat , a dog , and a pipe or two , enough to eat a\n",
      "ed him . I didn ' t encourage him . A dog like that don ' t want any encouragem\n",
      " with eggs and bacon , irritating the dog , or flirting with the slavey , inste\n",
      "dly . He would take bronchitis in the dog - days , and have hay - fever at Chri\n",
      "by the lady of the house ? That china dog that ornaments the bedroom of my furn\n",
      "my furnished lodgings . It is a white dog . Its eyes blue . Its nose is a delic\n",
      "me it is more than probable that that dog will be dug up from somewhere or othe\n",
      "s age , do not see the beauty of that dog . We are too familiar with it . It is\n",
      "o our eyes . So it is with that china dog . In 2288 people will gush over it . \n",
      " one another , and we beamed upon the dog , too . We loved each other , we love\n",
      "INE TO DRINK THE RIVER . - A PEACEFUL DOG . - STRANGE DISAPPEARANCE OF HARRIS A\n",
      "life , with care . I do not blame the dog ( contenting myself , as a rule , wit\n",
      "but mangy about the middle ; a bull - dog , a few Lowther Arcade sort of animal\n",
      "chained up there , between the bull - dog and the poodle . He sat and looked ab\n",
      "d dignified . He looked at the bull - dog , sleeping dreamlessly on his right .\n",
      "his own place , and caught the bull - dog by the ear , and tried to throw him a\n",
      "ed to throw him away ; and the bull - dog , a curiously impartial animal , went\n",
      "d , and snatched up that sweet little dog of hers ( he had laid the tyke up for\n",
      "have chilled the heart of the boldest dog . He stopped abruptly , and looked ba\n",
      "' s boy , with basket . Long - haired dog . Cheesemonger ' s boy , with basket \n",
      "owards us on the sluggish current , a dog . It was one of the quietest and peac\n",
      "dogs I have ever seen . I never met a dog who seemed more contented - more easy\n"
     ]
    }
   ],
   "source": [
    "textList.concordance(\"dog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using \"similar\" helps us discover what other words appear in a similar range of contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "river man thing time water night day bank lock way morning things boy\n",
      "room matter world air city business kettle\n"
     ]
    }
   ],
   "source": [
    "textList.similar(\"boat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "river boat thing time room bank morning night man things sea lock it\n",
      "other way place house subject them matter\n"
     ]
    }
   ],
   "source": [
    "textList.similar(\"water\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bit man long morning change dream body widow party trout boat harris\n",
      "hundred rest week river mean he out is\n"
     ]
    }
   ],
   "source": [
    "textList.similar(\"dog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positional information helps determine the location of a word in the text: how many words from the beginning it appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "textList.dispersion_plot([\"boat\", \"dog\", \"river\", \"lunch\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By default tokenization includes all surrounting punctuation charachters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81185"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(textList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can invoke RegexpTokenizer to eliminate punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68364"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This will match any word characters until it reaches a non-word character, like a space\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokens = tokenizer.tokenize(bk_3boat)\n",
    "\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measuring lexical diversity: dividing unique words by overall words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09222146948327893"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(textList)) / len(textList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lex_diversity_pct(text):\n",
    "    return (len(set(textList)) / len(textList))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.222146948327893"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex_diversity_pct(textList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text normalization with stemming and lemmatization\n",
    "\n",
    "The goal of both stemming and lemmatization is to reduce inflectional forms and sometimes derivationally related forms of a word to a common base form. For instance:\n",
    "\n",
    "    am, are, is =>  be\n",
    "    dog, dogs, dog's, dogs' => dog\n",
    "\n",
    "The result of this mapping of text will be something like:\n",
    "\n",
    "    the girl's dogs are different breeds => the girl dog be differ breed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "lancaster = nltk.LancasterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting lists to strings to simplify displaying / visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_l = (words_lc[0:50])\n",
    "words_s = ', '.join(words_l)\n",
    "type (words_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['three', 'men', 'boat', 'say', 'nothing', 'dog', 'three', 'men', 'boat', 'jerome', 'jerome', 'chapter', 'three', 'invalids', 'sufferings', 'george', 'harris', 'victim', 'one', 'hundred', 'seven', 'fatal', 'maladies', 'useful', 'prescriptions', 'cure', 'liver', 'complaint', 'children', 'agree', 'overworked', 'need', 'rest', 'week', 'rolling', 'deep', 'george', 'suggests', 'river', 'montmorency', 'lodges', 'objection', 'original', 'motion', 'carried', 'majority', 'three', 'one', 'four', 'us']\n"
     ]
    }
   ],
   "source": [
    "print (words_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming usually refers to a crude heuristic process that chops off the ends of words in the hope of achieving this goal correctly most of the time, and often includes the removal of derivational affixes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['three', 'men', 'boat', 'say', 'noth', 'dog', 'three', 'men', 'boat', 'jerom', 'jerom', 'chapter', 'three', 'invalid', 'suffer', 'georg', 'harri', 'victim', 'one', 'hundr', 'seven', 'fatal', 'maladi', 'use', 'prescript', 'cure', 'liver', 'complaint', 'children', 'agre', 'overwork', 'need', 'rest', 'week', 'roll', 'deep', 'georg', 'suggest', 'river', 'montmor', 'lodg', 'object', 'origin', 'motion', 'carri', 'major', 'three', 'one', 'four', 'us']\n"
     ]
    }
   ],
   "source": [
    "print([porter.stem(t) for t in words_lc[0:50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['three', 'men', 'boat', 'say', 'noth', 'dog', 'three', 'men', 'boat', 'jerom', 'jerom', 'chapt', 'three', 'invalid', 'suff', 'georg', 'har', 'victim', 'on', 'hundr', 'sev', 'fat', 'malady', 'us', 'prescrib', 'cur', 'liv', 'complaint', 'childr', 'agr', 'overwork', 'nee', 'rest', 'week', 'rol', 'deep', 'georg', 'suggest', 'riv', 'montm', 'lodg', 'object', 'origin', 'mot', 'carry', 'maj', 'three', 'on', 'four', 'us']\n"
     ]
    }
   ],
   "source": [
    "print([lancaster.stem(t) for t in words_lc[0:50]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma.\n",
    "\n",
    "The WordNet lemmatizer only removes affixes if the resulting word is in its dictionary. The dictionary checking makes lemmatizers significantly slower than stemmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['three', 'men', 'boat', 'say', 'nothing', 'dog', 'three', 'men', 'boat', 'jerome', 'jerome', 'chapter', 'three', 'invalids', 'sufferings', 'george', 'harris', 'victim', 'one', 'hundred', 'seven', 'fatal', 'maladies', 'useful', 'prescriptions', 'cure', 'liver', 'complaint', 'children', 'agree', 'overworked', 'need', 'rest', 'week', 'rolling', 'deep', 'george', 'suggests', 'river', 'montmorency', 'lodges', 'objection', 'original', 'motion', 'carried', 'majority', 'three', 'one', 'four', 'us']\n"
     ]
    }
   ],
   "source": [
    "print (words_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['three', 'men', 'boat', 'say', 'nothing', 'dog', 'three', 'men', 'boat', 'jerome', 'jerome', 'chapter', 'three', 'invalid', 'suffering', 'george', 'harris', 'victim', 'one', 'hundred', 'seven', 'fatal', 'malady', 'useful', 'prescription', 'cure', 'liver', 'complaint', 'child', 'agree', 'overworked', 'need', 'rest', 'week', 'rolling', 'deep', 'george', 'suggests', 'river', 'montmorency', 'lodge', 'objection', 'original', 'motion', 'carried', 'majority', 'three', 'one', 'four', 'u']\n"
     ]
    }
   ],
   "source": [
    "print([wnl.lemmatize(t) for t in words_lc[0:50]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can use help function to get explanations of endividual tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "uc1 = \"The University of Chicago is a private research university in Chicago, Illinois\"\n",
    "uc2 = \"It is one of the world's leading and most influential institutions of higher learning, with top-ten positions in numerous rankings and measures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('University', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Chicago', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('private', 'JJ'),\n",
       " ('research', 'NN'),\n",
       " ('university', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('Chicago', 'NNP'),\n",
       " (',', ','),\n",
       " ('Illinois', 'NNP')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.tokenize.word_tokenize(uc1)\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('IN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('It', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('one', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('world', 'NN'),\n",
       " (\"'s\", 'POS'),\n",
       " ('leading', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('most', 'JJS'),\n",
       " ('influential', 'JJ'),\n",
       " ('institutions', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('higher', 'JJR'),\n",
       " ('learning', 'NN'),\n",
       " (',', ','),\n",
       " ('with', 'IN'),\n",
       " ('top-ten', 'JJ'),\n",
       " ('positions', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('numerous', 'JJ'),\n",
       " ('rankings', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('measures', 'NNS')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.tokenize.word_tokenize(uc2)\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC: conjunction, coordinating\n",
      "    & 'n and both but either et for less minus neither nor or plus so\n",
      "    therefore times v. versus vs. whether yet\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('CC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list all possible tags and values\n",
    "# nltk.help.upenn_tagset('.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading from URL\n",
    "#### BeautifulSoup to clean up meta-tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/University_of_Chicago\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "page = urllib.request.urlopen(url)\n",
    "soup = BeautifulSoup(page.read(), \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for classes on October 1, 1892.[39]  Harper worked on building up the faculty and in two years he had a faculty of 120, including eight former university or college presidents.[44]  Harper was an accomplished scholar (Semiticist) and a member of the Baptist clergy who believed that a great university should maintain the study of faith as a central focus.[45] To fulfill this commitment, he brought the Baptist seminary that had begun as an independent school \"alongside\" the Old University of Chicago and separated from the old school decades earlier to Morgan Park. This became the Divinity School in 1891, the first professional school at the University of Chicago.[35]: 20–22 \n",
      "Harper recruited acclaimed Yale baseball and football player Amos Alonzo Stagg from the Young Men's Christian Association training school at Springfield to coach the school's football program. Stagg was given a position on the faculty, the first such athletic position in the United States. While coaching at the university, Stagg invented the numbered football jersey, the huddle, and the lighted playing field.  Stagg is the namesake of the university's Stagg Field.[46]\n",
      "The business school was founded in 1898,[47] and the law school was founded in 1902.[48] Harper died in 1906[49] and was replaced by a succession of three presidents whose tenures lasted until 1929.[50] During this period, the Oriental Institute was founded to support and interpret archeological work in what was then called the Near East.[51]\n",
      "In the 1890s, the university, fearful that its vast resources would injure smaller schools by drawing away good students, affiliated with several regional colleges and universities: Des Moines College, Kalamazoo College, Butler University, and Stetson University. In 1896, the university affiliated with Shimer College in Mount Carroll, Illinois. Under the terms of the affiliation, the schools were required to have courses of study comparable to those at the university, to notify the university early of any contemplated faculty appointments or dismissals, to make no faculty appointment\n"
     ]
    }
   ],
   "source": [
    "uc_wiki = (soup.get_text())\n",
    "#print (type(uc_wiki))\n",
    "print (uc_wiki[6910:9000]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Even after BeautifulSoup we are left with a lot of garbade - mostly punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['of', 'Chicago', 'team', 'that', 'worked', 'on', 'the', 'production', 'of', 'the', 'world', \"'s\", 'first', 'human-caused', 'self-sustaining', 'nuclear', 'reaction', ',', 'including', 'Enrico', 'Fermi', 'in', 'the', 'front', 'row', 'and', 'Leó', 'Szilárd', 'in', 'the', 'second', '.', 'Money', 'that', 'had', 'been', 'raised', 'during', 'the', '1920s', 'and', 'financial', 'backing', 'from', 'the', 'Rockefeller', 'Foundation', 'helped', 'the', 'school', 'to', 'survive', 'through', 'the', 'Great', 'Depression', '.', '[', '54', ']', 'Nonetheless', ',', 'in', '1933', ',', 'Hutchins', 'proposed', 'an', 'unsuccessful', 'plan', 'to', 'merge', 'the', 'University', 'of', 'Chicago', 'and', 'Northwestern', 'University', 'into', 'a', 'single', 'university', '.', '[', '57', ']', 'During', 'World', 'War', 'II', ',', 'the', 'university', \"'s\", 'Metallurgical', 'Laboratory', 'made', 'ground-breaking', 'contributions']\n"
     ]
    }
   ],
   "source": [
    "uc_wiki_tokens = nltk.tokenize.word_tokenize(uc_wiki)\n",
    "uc_wiki_tokens_uncleaned = uc_wiki_tokens\n",
    "print (uc_wiki_tokens[2000:2100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('University', 329),\n",
       " ('Chicago', 321),\n",
       " ('The', 198),\n",
       " ('Retrieved', 177),\n",
       " ('Archived', 137),\n",
       " ('original', 134),\n",
       " ('university', 129),\n",
       " ('School', 76),\n",
       " ('College', 73),\n",
       " ('September', 57)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stopwords = stopwords.words('english')\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# Remove single-character tokens (mostly punctuation)\n",
    "uc_wiki_tokens = [word for word in uc_wiki_tokens if len(word) > 1]\n",
    "\n",
    "# Remove punctuation\n",
    "uc_wiki_tokens = [word for word in uc_wiki_tokens if word.isalpha()]\n",
    "\n",
    "# Remove stopwords\n",
    "uc_wiki_tokens_no_stopwords = [word for word in uc_wiki_tokens if word not in stopwords]\n",
    "\n",
    "fdist = nltk.FreqDist(uc_wiki_tokens_no_stopwords)\n",
    "\n",
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the results of our cleaned web scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleanest version with all noise and stopwords removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['University', 'Chicago', 'Wikipedia', 'University', 'Chicago', 'From', 'Wikipedia', 'free', 'encyclopedia', 'Jump', 'navigation', 'Jump', 'search', 'Private', 'university', 'Chicago', 'Illinois', 'The', 'University', 'ChicagoLatin', 'Universitas', 'ChicaginiensisMottoCrescat', 'scientia', 'vita', 'excolatur', 'Latin', 'Motto', 'English', 'Let', 'knowledge', 'grow', 'human', 'life', 'enriched', 'TypePrivate', 'research', 'AccreditationHLCAcademic', 'billion', 'PresidentA', 'Paul', 'AlivisatosProvostKa', 'Yee', 'Christina', 'LeeAcademic', 'Administrative', 'including', 'employees', 'The', 'University', 'Chicago', 'Medical', 'Center', 'LocationChicago', 'Illinois', 'United', 'City', 'acres', 'ha', 'main', 'campus', 'Warren', 'Woods', 'Ecological', 'Field', 'Station', 'Warren', 'Woods', 'State', 'Park', 'acres', 'ha', 'NewspaperThe', 'Chicago', 'MaroonColors', 'Maroon', 'NicknameMaroonsSporting', 'affiliationsNCAA', 'Division', 'III', 'UAAMascotPhil', 'The', 'University', 'Chicago', 'UChicago', 'Chicago', 'UChi', 'private', 'research', 'university', 'Chicago', 'Illinois', 'Its', 'main', 'campus', 'located', 'Chicago', 'Hyde', 'Park', 'neighborhood', 'The']\n"
     ]
    }
   ],
   "source": [
    "uc_wiki_text_no_stopwords = nltk.Text(uc_wiki_tokens_no_stopwords)\n",
    "print (uc_wiki_text_no_stopwords[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modest cleaning - only punctuation and noise - all stopwords left intact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['University', 'of', 'Chicago', 'Wikipedia', 'University', 'of', 'Chicago', 'From', 'Wikipedia', 'the', 'free', 'encyclopedia', 'Jump', 'to', 'navigation', 'Jump', 'to', 'search', 'Private', 'university', 'in', 'Chicago', 'Illinois', 'The', 'University', 'of', 'ChicagoLatin', 'Universitas', 'ChicaginiensisMottoCrescat', 'scientia', 'vita', 'excolatur', 'Latin', 'Motto', 'in', 'English', 'Let', 'knowledge', 'grow', 'from', 'more', 'to', 'more', 'and', 'so', 'be', 'human', 'life', 'enriched', 'TypePrivate', 'research', 'AccreditationHLCAcademic', 'billion', 'PresidentA', 'Paul', 'AlivisatosProvostKa', 'Yee', 'Christina', 'LeeAcademic', 'Administrative', 'including', 'employees', 'of', 'The', 'University', 'of', 'Chicago', 'Medical', 'Center', 'LocationChicago', 'Illinois', 'United', 'City', 'acres', 'ha', 'main', 'campus', 'Warren', 'Woods', 'Ecological', 'Field', 'Station', 'Warren', 'Woods', 'State', 'Park', 'acres', 'ha', 'NewspaperThe', 'Chicago', 'MaroonColors', 'Maroon', 'NicknameMaroonsSporting', 'affiliationsNCAA', 'Division', 'III', 'UAAMascotPhil', 'the', 'The', 'University']\n"
     ]
    }
   ],
   "source": [
    "uc_wiki_text_cleaned = nltk.Text(uc_wiki_tokens)\n",
    "print (uc_wiki_text_cleaned[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No cleaning done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['University', 'of', 'Chicago', '-', 'Wikipedia', 'University', 'of', 'Chicago', 'From', 'Wikipedia', ',', 'the', 'free', 'encyclopedia', 'Jump', 'to', 'navigation', 'Jump', 'to', 'search', 'Private', 'university', 'in', 'Chicago', ',', 'Illinois', 'The', 'University', 'of', 'ChicagoLatin', ':', 'Universitas', 'ChicaginiensisMottoCrescat', 'scientia', ';', 'vita', 'excolatur', '(', 'Latin', ')', 'Motto', 'in', 'English', \"''\", 'Let', 'knowledge', 'grow', 'from', 'more', 'to', 'more', ';', 'and', 'so', 'be', 'human', 'life', 'enriched', '.', '``', '[', '1', ']', 'TypePrivate', 'research', 'universityEstablished1890', '[', '1856', ']', '(', '1890', '[', '1856', ']', ')', '[', '1', ']', '[', '2', ']', 'AccreditationHLCAcademic', 'affiliationsAAUNAICUURASpace-grantEndowment', '$', '11.6', 'billion', '(', '2021', ')', '[', '3', ']', 'PresidentA', '.', 'Paul', 'AlivisatosProvostKa', 'Yee', 'Christina', 'LeeAcademic', 'staff2,859']\n"
     ]
    }
   ],
   "source": [
    "uc_wiki_text_raw = nltk.Text(uc_wiki_tokens_uncleaned)\n",
    "print (uc_wiki_text_raw[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying simlarity function - which option produces best results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleanest version with all noise and stopwords removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site chicago illinois the campus maroon uchicago located college\n",
      "science history arts sororities buildings classes reputation economist\n",
      "chairman kind spurs\n"
     ]
    }
   ],
   "source": [
    "uc_wiki_text_no_stopwords.similar('university')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modest cleaning - only punctuation and noise - all stopwords left intact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "college class chicago world school faculty board campus history arts\n",
      "law as development president professor study institute office team\n",
      "site\n"
     ]
    }
   ],
   "source": [
    "uc_wiki_text_cleaned.similar('university')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No cleaning done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "college class chicago world school faculty board campus arts law as\n",
      "development history president professor study institute office site\n",
      "new\n"
     ]
    }
   ],
   "source": [
    "uc_wiki_text_raw.similar('university')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging our web page with POS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In order for the tagger to be effective, it has to tag each word based on the word itself, as well as its context within a sentence. \n",
    "Depending on your corpus, certain taggers perform better the others.  Like with SPSS TA dictionaries, you can start with pre-trained POS Tagger and then try multiple different options to see which one will perform best for you.\n",
    "You can also customize and train your own taggers to match your particular corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "uc_wiki_tagged = nltk.pos_tag(uc_wiki_text_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(uc_wiki_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('University', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Chicago', 'NNP'),\n",
       " ('Wikipedia', 'NNP'),\n",
       " ('University', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Chicago', 'NNP'),\n",
       " ('From', 'NNP'),\n",
       " ('Wikipedia', 'NNP'),\n",
       " ('the', 'DT')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uc_wiki_tagged[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring alternative text analysis packages: TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(uc_wiki)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part of speech tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('9', 'CD'),\n",
       " (']', 'VBD'),\n",
       " ('The', 'DT'),\n",
       " ('University', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Chicago', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('consistently', 'RB'),\n",
       " ('ranked', 'VBN'),\n",
       " ('among', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('best', 'JJS'),\n",
       " ('universities', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('world', 'NN'),\n",
       " ('[', 'VBZ'),\n",
       " ('10', 'CD'),\n",
       " (']', 'NN'),\n",
       " ('[', 'VBD')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.tags[200:220]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To process  cleaned-up version from NLTK we will have to convert text from nltk.text.Text to String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.text.Text"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(uc_wiki_text_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "words_list = (uc_wiki_text_cleaned[0:])\n",
    "words_string = ', '.join(words)\n",
    "print(type(words_list))\n",
    "print(type(words_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(words_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POS Tagging with TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TO', 'NNP'),\n",
       " ('ONE', 'NNP'),\n",
       " ('THERE', 'NNP'),\n",
       " ('were', 'VBD'),\n",
       " ('four', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('us', 'PRP'),\n",
       " ('George', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('William', 'NNP'),\n",
       " ('Samuel', 'NNP'),\n",
       " ('Harris', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('myself', 'PRP'),\n",
       " ('and', 'CC'),\n",
       " ('Montmorency', 'NNP'),\n",
       " ('We', 'PRP'),\n",
       " ('were', 'VBD'),\n",
       " ('sitting', 'VBG'),\n",
       " ('in', 'IN')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.tags[70:90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('four', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('us', 'PRP'),\n",
       " ('George', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('William', 'NNP'),\n",
       " ('Samuel', 'NNP'),\n",
       " ('Harris', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('myself', 'PRP'),\n",
       " ('and', 'CC'),\n",
       " ('Montmorency', 'NNP'),\n",
       " ('We', 'PRP'),\n",
       " ('were', 'VBD'),\n",
       " ('sitting', 'VBG'),\n",
       " ('in', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('room', 'NN'),\n",
       " ('smoking', 'NN'),\n",
       " ('and', 'CC')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = nltk.tokenize.word_tokenize(bk_3boat)\n",
    "words_string = ', '.join(words)\n",
    "blob = TextBlob(words_string)\n",
    "\n",
    "blob.tags[80:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tripping on the capitalized header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('THREE', 'CD'),\n",
       " ('MEN', 'NNP'),\n",
       " ('IN', 'NNP'),\n",
       " ('A', 'NNP'),\n",
       " ('BOAT', 'NNP'),\n",
       " ('TO', 'NNP'),\n",
       " ('SAY', 'NNP'),\n",
       " ('NOTHING', 'NNP'),\n",
       " ('OF', 'NNP'),\n",
       " ('THE', 'NNP')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.tags[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['three', 'men', 'in', 'boat', 'to', 'say', 'nothing', 'of', 'the', 'dog', 'men', 'boat', 'jerome', 'k.', 'jerome', 'chapter', 'three', 'invalids', 'sufferings', 'of', 'george', 'and', 'harris', 'victim', 'to', 'one', 'hundred', 'and', 'seven', 'fatal', 'maladies', 'useful', 'prescriptions', 'cure', 'for', 'liver', 'complaint', 'in', 'children', 'we', 'agree', 'that', 'we', 'are', 'overworked', 'and', 'need', 'rest', 'week', 'on'])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.noun_phrases[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Be careful with embedded functions to pluralize and singularize the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = TextBlob(words_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['three', 'men', 'boat', 'say', 'nothing', 'dog', 'three', 'men', 'boat', 'jerome', 'jerome', 'chapter', 'three', 'invalids', 'sufferings', 'george', 'harris', 'victim', 'one', 'hundred', 'seven', 'fatal', 'maladies', 'useful', 'prescriptions', 'cure', 'liver', 'complaint', 'children', 'agree', 'overworked', 'need', 'rest', 'week', 'rolling', 'deep', 'george', 'suggests', 'river', 'montmorency', 'lodges', 'objection', 'original', 'motion', 'carried', 'majority', 'three', 'one', 'four', 'us']\n"
     ]
    }
   ],
   "source": [
    "print(words_l[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['three', 'man', 'boat', 'say', 'nothing', 'dog', 'three', 'man', 'boat', 'jerome', 'jerome', 'chapter', 'three', 'invalid', 'suffering', 'george', 'harri', 'victim', 'one', 'hundred', 'seven', 'fatal', 'malady', 'useful', 'prescription', 'cure', 'liver', 'complaint', 'child', 'agree', 'overworked', 'need', 'rest', 'week', 'rolling', 'deep', 'george', 'suggest', 'river', 'montmorency', 'lodge', 'objection', 'original', 'motion', 'carried', 'majority', 'three', 'one', 'fmy', 'u'])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.words[:100].singularize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['three', 'men', 'boat', 'say', 'nothing', 'dog', 'three', 'men', 'boat', 'jerome', 'jerome', 'chapter', 'three', 'invalids', 'sufferings', 'george', 'harris', 'victim', 'one', 'hundred', 'seven', 'fatal', 'maladies', 'useful', 'prescriptions', 'cure', 'liver', 'complaint', 'children', 'agree', 'overworked', 'need', 'rest', 'week', 'rolling', 'deep', 'george', 'suggests', 'river', 'montmorency', 'lodges', 'objection', 'original', 'motion', 'carried', 'majority', 'three', 'one', 'four', 'us']\n"
     ]
    }
   ],
   "source": [
    "print(words_l[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['threes', 'mens', 'boats', 'says', 'nothings', 'dogs', 'threes', 'mens', 'boats', 'jeromes', 'jeromes', 'chapters', 'threes', 'invalidss', 'sufferingss', 'georges', 'harriss', 'victims', 'ones', 'hundreds', 'sevens', 'fatals', 'maladiess', 'usefuls', 'prescriptionss', 'cures', 'livers', 'complaints', 'childrens', 'agrees', 'overworkeds', 'needs', 'rests', 'weeks', 'rollings', 'deeps', 'georges', 'suggestss', 'rivers', 'montmorencies', 'lodgess', 'objections', 'originals', 'motions', 'carrieds', 'majorities', 'threes', 'ones', 'fours', 'uss'])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.words[0:100].pluralize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['three', 'men', 'boat', 'say', 'nothing', 'dog', 'three', 'men', 'boat', 'jerome', 'jerome', 'chapter', 'three', 'invalids', 'sufferings', 'george', 'harris', 'victim', 'one', 'hundred', 'seven', 'fatal', 'maladies', 'useful', 'prescriptions', 'cure', 'liver', 'complaint', 'children', 'agree', 'overworked', 'need', 'rest', 'week', 'rolling', 'deep', 'george', 'suggests', 'river', 'montmorency', 'lodges', 'objection', 'original', 'motion', 'carried', 'majority', 'three', 'one', 'four', 'us'])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.words[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['three', 'men', 'boat', 'say', 'nothing', 'dog', 'three', 'men', 'boat', 'jerome', 'jerome', 'chapter', 'three', 'invalid', 'suffering', 'george', 'harris', 'victim', 'one', 'hundred', 'seven', 'fatal', 'malady', 'useful', 'prescription', 'cure', 'liver', 'complaint', 'child', 'agree', 'overworked', 'need', 'rest', 'week', 'rolling', 'deep', 'george', 'suggests', 'river', 'montmorency', 'lodge', 'objection', 'original', 'motion', 'carried', 'majority', 'three', 'one', 'four', 'u'])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.words[0:100].lemmatize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_wiki = TextBlob(uc_wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Harper', 'worked', 'on', 'building', 'up', 'the', 'faculty', 'and', 'in', 'two', 'years', 'he', 'had', 'a', 'faculty', 'of', '120', 'including', 'eight', 'former', 'university', 'or', 'college', 'presidents', '44', 'Harper', 'was', 'an', 'accomplished', 'scholar', 'Semiticist', 'and', 'a', 'member', 'of', 'the', 'Baptist', 'clergy', 'who', 'believed', 'that', 'a', 'great', 'university', 'should', 'maintain', 'the', 'study', 'of', 'faith', 'as', 'a', 'central', 'focus', '45', 'To', 'fulfill', 'this', 'commitment', 'he']\n"
     ]
    }
   ],
   "source": [
    "b_words = blob_wiki.words\n",
    "print (b_words[1020:1080])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'class', '1.1.3', 'is', 'almost', 'over', 'Time', 'to', 'go', 'party', 'now']\n"
     ]
    }
   ],
   "source": [
    "blob_custom = TextBlob('The class 1.1.3 is almost over!!!  Time to go party now.')\n",
    "b_words = blob_custom.words\n",
    "print (b_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split to sentenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sentence(\"[24]  Advances in chemistry led to the \"radiocarbon revolution\" in the carbon-14 dating of ancient life and objects.\"), Sentence(\"[25] The university research efforts include administration of Fermi National Accelerator Laboratory and Argonne National Laboratory, as well as the Marine Biological Laboratory.\"), Sentence(\"The university is also home to the University of Chicago Press, the largest university press in the United States.\"), Sentence(\"[26]\n",
      "The University of Chicago's students, faculty, and staff include 94 Nobel laureates, among the highest of any university in the world.\"), Sentence(\"[27] The university's faculty members and alumni also include 10 Fields Medalists,[28] 4 Turing Award winners, 52 MacArthur Fellows,[29] 26 Marshall Scholars,[30] 53 Rhodes Scholars,[31] 27 Pulitzer Prize winners,[32] 20 National Humanities Medalists,[33] 29 living billionaire graduates,[34] and eight Olympic medalists.\")]\n"
     ]
    }
   ],
   "source": [
    "b_sentences = blob_wiki.sentences\n",
    "print (b_sentences[10:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sentence(\"I need to go to Dr. now NLP is So.\"), Sentence(\"boring...\"), Sentence(\"I want to end this Zoom session now.\")]\n"
     ]
    }
   ],
   "source": [
    "blob_custom = TextBlob('''I need to go to Dr. now NLP is So. boring... I want to end this Zoom session now.''')\n",
    "b_sentences = blob_custom.sentences\n",
    "print (b_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sentence(\"The class 1, 2, etc.\"), Sentence(\"are almost over!!!\"), Sentence(\"Time to go to to U.S.A. next 34 Dr. Yuri's party 1.2. now.\")]\n"
     ]
    }
   ],
   "source": [
    "blob_custom = TextBlob('''The class 1, 2, etc. are almost over!!!  Time to go to to U.S.A. next 34 Dr. Yuri's party 1.2. now.''')\n",
    "b_sentences = blob_custom.sentences\n",
    "print (b_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mon, 20 June 2022 19:57:06'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "\n",
    "datetime.datetime.now(pytz.timezone('US/Central')).strftime(\"%a, %d %B %Y %H:%M:%S\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
