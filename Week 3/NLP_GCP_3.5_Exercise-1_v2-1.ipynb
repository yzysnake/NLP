{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Class 3 Exercise 1:\n",
    "- Read tweets into Pandas Dataframe\n",
    "- Identify Bigrams and Trigrams for the top frequently mentioned AI / ML / NLP technologies\n",
    "\n",
    "**Suggestions:** \n",
    "- Eliminate URLs, Mentions, Hashtags, RTs and newline characters\n",
    "- Clean-up n-grams by eliminating punctuation, number, stopwords and lowercasing the text\n",
    "- Add custom stopwords filters to get more relevant results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-19T01:54:08.112790Z",
     "start_time": "2024-01-19T01:54:08.106675Z"
    }
   },
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('popular', halt_on_error=False)\n",
    "#nltk.download('all', halt_on_error=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-19T01:54:14.172837Z",
     "start_time": "2024-01-19T01:54:09.703019Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk as nltk\n",
    "import nltk.corpus  \n",
    "from nltk.text import Text\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-19T01:54:14.191027Z",
     "start_time": "2024-01-19T01:54:14.173561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.4 (main, Jul  5 2023, 09:00:44) [Clang 14.0.6 ]\n"
     ]
    }
   ],
   "source": [
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-19T01:54:19.311163Z",
     "start_time": "2024-01-19T01:54:16.067232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset records: 100043, Dataset columns: 7\n"
     ]
    }
   ],
   "source": [
    "url = 'https://storage.googleapis.com/msca-bdp-data-open/tweets/tweets_ai_ml_nlp.json'\n",
    "tweets = pd.read_json(url, orient='records', lines=True)\n",
    "\n",
    "print(f'Dataset records: {tweets.shape[0]}, Dataset columns: {tweets.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-19T01:54:19.419017Z",
     "start_time": "2024-01-19T01:54:19.310861Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                    id lang       date           name  \\\n0  1529094548005064705   en 2022-05-24         odol‚òòÔ∏è   \n1  1529094585942568960   en 2022-05-24   Paijo s'Bejo   \n2  1529094709771051013   en 2022-05-24  üçÄGingüçÄ6Ô∏è‚É£5Ô∏è‚É£üéπ   \n3  1529094719120510976   en 2022-05-24   Ultra mildüóØüí´   \n4  1529094845393907712   en 2022-05-24        Ohayouüåº   \n\n                                                text  \\\n0  RT @Frank4NC: CodyFight is a must watch and mu...   \n1  RT @Bakercrypt0: Wonderful day to everybody! ‚ú®...   \n2  RT @Frank4NC: CodyFight is a must watch and mu...   \n3  RT @codyfight: Codyfight is a place where Huma...   \n4  RT @ninasimonic: Wonderful day to everybody! ‚ú®...   \n\n                                       extended_text  \\\n0  CodyFight is a must watch and must EARN! Get r...   \n1  Wonderful day to everybody! ‚ú®ü´∂\\n\\nThe trailer ...   \n2  CodyFight is a must watch and must EARN! Get r...   \n3  Codyfight is a place where Humans and #AI comp...   \n4  Wonderful day to everybody! ‚ú®ü´∂\\n\\nTheir traile...   \n\n                                         quoted_text  \n0  Codyfight is a place where Humans and #AI comp...  \n1  Codyfight is a place where Humans and #AI comp...  \n2  Codyfight is a place where Humans and #AI comp...  \n3                                               None  \n4  Codyfight is a place where Humans and #AI comp...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>lang</th>\n      <th>date</th>\n      <th>name</th>\n      <th>text</th>\n      <th>extended_text</th>\n      <th>quoted_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1529094548005064705</td>\n      <td>en</td>\n      <td>2022-05-24</td>\n      <td>odol‚òòÔ∏è</td>\n      <td>RT @Frank4NC: CodyFight is a must watch and mu...</td>\n      <td>CodyFight is a must watch and must EARN! Get r...</td>\n      <td>Codyfight is a place where Humans and #AI comp...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1529094585942568960</td>\n      <td>en</td>\n      <td>2022-05-24</td>\n      <td>Paijo s'Bejo</td>\n      <td>RT @Bakercrypt0: Wonderful day to everybody! ‚ú®...</td>\n      <td>Wonderful day to everybody! ‚ú®ü´∂\\n\\nThe trailer ...</td>\n      <td>Codyfight is a place where Humans and #AI comp...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1529094709771051013</td>\n      <td>en</td>\n      <td>2022-05-24</td>\n      <td>üçÄGingüçÄ6Ô∏è‚É£5Ô∏è‚É£üéπ</td>\n      <td>RT @Frank4NC: CodyFight is a must watch and mu...</td>\n      <td>CodyFight is a must watch and must EARN! Get r...</td>\n      <td>Codyfight is a place where Humans and #AI comp...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1529094719120510976</td>\n      <td>en</td>\n      <td>2022-05-24</td>\n      <td>Ultra mildüóØüí´</td>\n      <td>RT @codyfight: Codyfight is a place where Huma...</td>\n      <td>Codyfight is a place where Humans and #AI comp...</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1529094845393907712</td>\n      <td>en</td>\n      <td>2022-05-24</td>\n      <td>Ohayouüåº</td>\n      <td>RT @ninasimonic: Wonderful day to everybody! ‚ú®...</td>\n      <td>Wonderful day to everybody! ‚ú®ü´∂\\n\\nTheir traile...</td>\n      <td>Codyfight is a place where Humans and #AI comp...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use TweetTokenizer to tokenize Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.7 s, sys: 260 ms, total: 28 s\n",
      "Wall time: 28 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(#programming, #coding)</td>\n",
       "      <td>7715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(#javascript, #reactjs)</td>\n",
       "      <td>7422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(#coding, #100daysofcode)</td>\n",
       "      <td>7088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(#iot, #iiot)</td>\n",
       "      <td>7002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(#bigdata, #analytics)</td>\n",
       "      <td>6132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(#ai, #machinelearning)</td>\n",
       "      <td>5430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(#python, #rstats)</td>\n",
       "      <td>4600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(#datascience, #ai)</td>\n",
       "      <td>4221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(#analytics, #datascience)</td>\n",
       "      <td>3924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(#tensorflow, #javascript)</td>\n",
       "      <td>3875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(#javascript, #python)</td>\n",
       "      <td>3861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(#ai, #iot)</td>\n",
       "      <td>3741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(#rstats, #tensorflow)</td>\n",
       "      <td>3694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(#python, #javascript)</td>\n",
       "      <td>3687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(#datascientist, #linux)</td>\n",
       "      <td>3545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(#100daysofcode, #python)</td>\n",
       "      <td>3460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(#machinelearning, #ai)</td>\n",
       "      <td>3349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(#linux, #programming)</td>\n",
       "      <td>3331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(#serverless, #datascientist)</td>\n",
       "      <td>3281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(machine, learning)</td>\n",
       "      <td>3279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Word  Frequency\n",
       "0         (#programming, #coding)       7715\n",
       "1         (#javascript, #reactjs)       7422\n",
       "2       (#coding, #100daysofcode)       7088\n",
       "3                   (#iot, #iiot)       7002\n",
       "4          (#bigdata, #analytics)       6132\n",
       "5         (#ai, #machinelearning)       5430\n",
       "6              (#python, #rstats)       4600\n",
       "7             (#datascience, #ai)       4221\n",
       "8      (#analytics, #datascience)       3924\n",
       "9      (#tensorflow, #javascript)       3875\n",
       "10         (#javascript, #python)       3861\n",
       "11                    (#ai, #iot)       3741\n",
       "12         (#rstats, #tensorflow)       3694\n",
       "13         (#python, #javascript)       3687\n",
       "14       (#datascientist, #linux)       3545\n",
       "15      (#100daysofcode, #python)       3460\n",
       "16        (#machinelearning, #ai)       3349\n",
       "17         (#linux, #programming)       3331\n",
       "18  (#serverless, #datascientist)       3281\n",
       "19            (machine, learning)       3279"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "top_N = 100\n",
    "\n",
    "tweet_text = tweets['extended_text'].str.lower().str.replace(r'\\|', ' ', regex=True).str.cat(sep=' ')\n",
    "\n",
    "\n",
    "# Use TweetTokenizer\n",
    "tweet_tokenizer = nltk.tokenize.TweetTokenizer()\n",
    "words = tweet_tokenizer.tokenize(tweet_text)\n",
    "\n",
    "#stopwords = stopwords.words('english')\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# Remove single-character tokens (mostly punctuation)\n",
    "words = [word for word in words if len(word) > 1]\n",
    "\n",
    "# Remove numbers\n",
    "words = [word for word in words if not word.isnumeric()]\n",
    "\n",
    "# Remove punctuation\n",
    "# words = [word for word in words if word.isalpha()]\n",
    "\n",
    "# Lowercase all words (default_stopwords are lowercase too)\n",
    "words = [word.lower() for word in words]\n",
    "\n",
    "# Remove stopwords\n",
    "words = [word for word in words if word not in stopwords]\n",
    "\n",
    "bgs = nltk.bigrams(words)\n",
    "\n",
    "#compute frequency distribution for all the bigrams in the text\n",
    "fdist_2 = nltk.FreqDist(bgs)\n",
    "\n",
    "fdist_2_df = pd.DataFrame(fdist_2.most_common(),\n",
    "                    columns=['Word', 'Frequency'])\n",
    "\n",
    "fdist_2_df.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-19T02:00:12.108848Z",
     "start_time": "2024-01-19T01:59:51.712616Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                               Word  Frequency\n0               (machine, learning)       3279\n1        (artificial, intelligence)       3069\n2                   (data, science)       2033\n3                 (free, middlemen)       1783\n4                       (job, sign)       1603\n5                       (need, job)       1546\n6                 (covid, insights)       1200\n7                 (analytics, team)       1172\n8             (insights, analytics)       1170\n9                  (deep, learning)       1045\n10                   (free, charge)        728\n11  (sign, https://t.co/rmerdjmv4h)        705\n12                  (latest, covid)        680\n13                    (team, using)        672\n14                (using, usafacts)        668\n15  (sign, https://t.co/rmerdk45vp)        663\n16                   (take, survey)        646\n17  (sign, https://t.co/o7lvlsl75x)        646\n18  (sign, https://t.co/o7lvlschxv)        640\n19                    (survey, win)        635",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Frequency</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(machine, learning)</td>\n      <td>3279</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(artificial, intelligence)</td>\n      <td>3069</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>(data, science)</td>\n      <td>2033</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(free, middlemen)</td>\n      <td>1783</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>(job, sign)</td>\n      <td>1603</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>(need, job)</td>\n      <td>1546</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>(covid, insights)</td>\n      <td>1200</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>(analytics, team)</td>\n      <td>1172</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>(insights, analytics)</td>\n      <td>1170</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>(deep, learning)</td>\n      <td>1045</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>(free, charge)</td>\n      <td>728</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>(sign, https://t.co/rmerdjmv4h)</td>\n      <td>705</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>(latest, covid)</td>\n      <td>680</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>(team, using)</td>\n      <td>672</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>(using, usafacts)</td>\n      <td>668</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>(sign, https://t.co/rmerdk45vp)</td>\n      <td>663</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>(take, survey)</td>\n      <td>646</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>(sign, https://t.co/o7lvlsl75x)</td>\n      <td>646</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>(sign, https://t.co/o7lvlschxv)</td>\n      <td>640</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>(survey, win)</td>\n      <td>635</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_N = 100\n",
    "\n",
    "tweet_text = tweets['extended_text'].str.lower().str.replace(r'\\|', ' ', regex=True).str.cat(sep=' ')\n",
    "\n",
    "# Use TweetTokenizer\n",
    "tweet_tokenizer = nltk.tokenize.TweetTokenizer()\n",
    "words = tweet_tokenizer.tokenize(tweet_text)\n",
    "\n",
    "# Set of stopwords\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# Remove single-character tokens (mostly punctuation)\n",
    "words = [word for word in words if len(word) > 1]\n",
    "\n",
    "# Remove numbers\n",
    "words = [word for word in words if not word.isnumeric()]\n",
    "\n",
    "# Lowercase all words (default_stopwords are lowercase too)\n",
    "words = [word.lower() for word in words]\n",
    "\n",
    "# Remove hashtags\n",
    "words = [word for word in words if not word.startswith('#')]\n",
    "\n",
    "# Remove stopwords\n",
    "words = [word for word in words if word not in stopwords]\n",
    "\n",
    "bgs = nltk.bigrams(words)\n",
    "\n",
    "# Compute frequency distribution for all the bigrams in the text\n",
    "fdist_2 = nltk.FreqDist(bgs)\n",
    "\n",
    "fdist_2_df = pd.DataFrame(fdist_2.most_common(), columns=['Word', 'Frequency'])\n",
    "\n",
    "fdist_2_df.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fri, 12 August 2022 16:13:33'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "\n",
    "datetime.datetime.now(pytz.timezone('US/Central')).strftime(\"%a, %d %B %Y %H:%M:%S\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
